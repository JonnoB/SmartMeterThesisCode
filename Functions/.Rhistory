data2 <- data2[complete.cases(data2),]
sweep(data2[,2:7], MARGIN=2, x, FUN = "/")
?sweep
sweep(as.array(data2[,2:7]), MARGIN=2, x, FUN = "/")
?array
as.array(data[,2:7])
sweep(as.matrix(data2[,2:7]), MARGIN=2, x, FUN = "/")
View(data2)
as.matrix(data[,2:7])
sapply(data,class)
sapply(data2,class)
as.matrix(as.numeric(data[,2:7]))
class(data[,2:7])
x <-  lapply(data2[,2:7], max)
x
x <-  lapply(data2[,2:7], data[,n]/max(n))
x <-  lapply(data2[,2:7], function(n)data[,n]/max(n))
x <-  lapply(data2[,2:7], function(n) data[,n]/max(data[,n]))
x <-  lapply(2:7, function(n) data[,n]/max(data[,n]))
sweep(as.matrix(data2[,2:7]), MARGIN=2, x, FUN = "/")
x <-  lapply(2:7, function(n) data[,n]/max(data[,n]))
dput(data2)
dput(data2[1:10,1:3])
x <- structure(list(Area.name = c("Barking and Dagenham", "Barnet",
"Bexley", "Brent", "Bromley", "Camden", "Croydon", "Ealing",
"Enfield", "Greenwich"), Median.House.Price..2014 = c(215000,
4e+05, 250000, 385000, 335000, 675000, 265000, 388000, 285000,
317000), Total.carbon.emissions..2013. = c(783.2, 1552.7, 1060.9,
1292.6, 1334.7, 1540.5, 1452.2, 1567.3, 1397.5, 1004.5)), .Names = c("Area.name",
"Median.House.Price..2014", "Total.carbon.emissions..2013."), row.names = 2:11, class = "data.frame")
n <- 2
data[,n]/max(data[,n])
n <- 3
data[,n]/max(data[,n])
data[,3]/max(data[,3])
max(data[,3])
x <-  lapply(2:7, function(n) data2[,n]/max(data2[,n]))
bind_cols(x)
x <-  lapply(2:7, function(n) as.data.frame(data2[,n]/max(data2[,n])))
bind_cols(x)
data2[,2:7] <- bind_cols(x)
View(data2)
names(data2)
x <-  lapply(c(2,3,5,6,7), function(n) as.data.frame(1/data2[,n])
data[,-c(1,4)] <- bind_cols(x)
x <-  lapply(c(2,3,5,6,7), function(n) as.data.frame(1/data2[,n]))
data[,-c(1,4)] <- bind_cols(x)
View(data2)
cite(caret)
cite("caret")
library(caret)
cite("caret")
library(caret)
cite(caret)
choose(7,1)
x2 <- 1 + choose(x,1) + choose(x,2)
x <- 2:7
x2 <- 1 + choose(x,1) + choose(x,2)
prod(x2)
2*prod(x2)
sqrt(28)
x <- c(3, 0, 5)
x <- c(3, 0, 5)
p=2
x2 <- (sum(x^p))^-p
sum(x^p)
x2 <- (sum(x^p))^(1/p)
p=3
x2 <- (sum(x^p))^(1/p)
p=2
x2 <- (sum(x^p))^(1/p)
p=20
x2 <- (sum(x^p))^(1/p)
0/5
sum(x^p)^y
sum(x^y)^p
p=4
y =2
sum(x^p)^y
sum(x^y)^p
```
x <- c(2, 3, 4,10)
p=2
y =0
x2 <- (sum(x^p))^(1/p)
x <- c(2, 3, 4,10)
p=2
y =0
(sum(x^p))^(1/p)
x <- c(2, 3, 4,10)
p=1
y =0
(sum(x^p))^(1/p)
x <- c(2, 3, 4,)
p=1
y =0
(sum(x^p))^(1/p)
x <- c(2, 3, 4,)
p=1
y =0
(sum(x^p))^(1/p)
x <- c(2, 3, 4)
p=1
y =0
(sum(x^p))^(1/p)
x <- c(2, 3, 4)
p=2
y =0
(sum(x^p))^(1/p)
x <- c(1, 1, 1)
p= c(1,2)
y =0
(sum(x^p))^(1/p)
x <- c(1, 1, 1)
p1= 1
p2 =2
c(  max(x),(sum(x^p2))^(1/p2),  (sum(x^p1))^(1/p1))
x <- c(.1, .1, .1)
p1= 1
p2 =2
c(  max(x),(sum(x^p2))^(1/p2),  (sum(x^p1))^(1/p1))
x <- c(0.9, 0.9, 0.9)
p1= 1
p2 =2
c(  max(x),(sum(x^p2))^(1/p2),  (sum(x^p1))^(1/p1))
x <- c(0.5, 0.5, 0.5)
p1= 1
p2 =2
c(  max(x),(sum(x^p2))^(1/p2),  (sum(x^p1))^(1/p1))
x <- c(0.33, 0.33, 0.33)
p1= 1
p2 =2
c(  max(x),(sum(x^p2))^(1/p2),  (sum(x^p1))^(1/p1))
x <- c(0, 0, 6)
p1= 1
p2 =2
c(  max(x),(sum(x^p2))^(1/p2),  (sum(x^p1))^(1/p1))
x <- 1:8
x2 <- 1 + choose(x,1) + choose(x,2)
x2
sum(x2)
2*prod(x2)
x <- 2:7
x2 <- 1 + choose(x,1) + choose(x,2)
x2
sum(x2)
prod(x2)*2
(6*9+4*5)/10
(6*9+2*5)/8
18*800000
3000000/25
x <- 2:7
x2 <- 1 + choose(x,1) + choose(x,2)
x2
2+sum(x2)
combn(1:4,4)
combn(letters[1:4], 2)
combn(letters[1:4], 3)
combn([1:4], 3)
combn(1:4, 3)
combn(1:4, 4)
combn(1:4, 1)
combn(1:4, 3)
expand.grid(0:1, 0:1, 0:1)
expand.grid(1:4, 1:4, 1:4)
combn(1:4,4)
combn(1:4)
combn(1:4,1)
combn(1:4,2)
combn(1:4,3)
permn(1:4,3)
require(gtools)
permutations(n = 9, r = 3, v = 1:9)
?permutations
permutations(n = 4, r = 4, v = 1:4)
R.Version()
install.packages(c("BH", "car", "caret", "digest", "earth", "ggplot2", "git2r", "htmltools", "knitr", "pbkrtest", "plotrix", "Rcpp", "rJava", "rmarkdown", "rstudioapi", "tidyr"))
install.packages(c("BH", "car", "caret", "digest", "earth", "ggplot2", "git2r", "htmltools", "knitr", "pbkrtest", "plotrix", "Rcpp", "rJava", "rmarkdown", "tidyr"))
1-(1-0.95)^21
1-(1-0.05)^21
log(756)
(0.7-0.45*0.35)/0.65
(0.7-0.45*0.35-0.9*0.15)/0.5
library(dplyr)
data.frame(numbers = 1:20) %>% mutate(log = log(numbers), other = numbers-1)
data.frame(numbers = (1:20)/20) %>% mutate(log = log(numbers), other = numbers-1)
?return
4/30
4/27
3/27
matrix(0, ,6,6)
matrix(0, 6,6)
mat1 <- matrix(0, 6,6)
mat1[-c(5:6), -c(1:2)]
mat1[-c(5:6), -c(1:2)] <- diag(4)
mat1
mat1 <- matrix(0, 6,6)
mat1[-c(5:6), -c(1:2)] <- diag(4)
mat1[1,2] <-1
mat1[5,1] <-1
mat1
mat1 <- matrix(0, 6,6)
mat1[-c(5:6), -c(1:2)] <- diag(4)
mat1[1,2] <-1
mat1[5,6] <-1
mat1
mat1 %*% mat1
mat1 %*% mat1 %*% mat1
mat1 %*% mat1 %*% mat1 %*% mat1
mat2 <- mat1 + t(mat1)
mat2
mat2 %*% mat2 %*% mat1
chord3 <- mat2 %*% mat2 %*% mat1
chord3 <- mat2 %*% mat2 %*% mat2
chord3
four <- chord3 %*% mat2
four
chord3 <- mat2 %*% mat2 #%*% mat2
chord3
chord3 >1
chord
chord3
chord3 >0
chord3 >1
chord3 >0
four
triang <- mat2
mat2
triang[-2, 2]
triang[-2, 2] <-1
triang
triang %*% triang
triang %*% triang %*% triang
triang %*% triang %*% triang %>% triang
triang %*% triang %*% triang %*% triang
mat2 %*% mat2 #%*% mat2
trace(chord3)
?trace
View(triang)
chird3
chord3
mat2 %*% mat2 %*% mat2 %*% mat2 %*% mat2
mat2
mat2 %*% mat2
mat2 %*% mat2 %*% mat2
mat2 %*% mat2 %*% mat2 %*% mat2
mat2 %*% mat2 %*% mat2 %*% mat2 %*% mat2
mat2 %*% mat2 %*% mat2 %*% mat2 %*% mat2 %*% mat2
22/6
22/12
22/11
mat2 %*% mat2
mat2 %*% mat2 %*% mat2
mat2 %*% mat2 %*% mat2 %*% mat2
mat2 %*% mat2
mat2 %*% mat2 %*% mat2 %*% mat2
mat2 %*% mat2 %*% mat2
mat2 %*% mat2
mat2 %*% mat2
mat2 %*% mat2 %*% mat2
mat2 %*% mat2
mat2
mat2 %*% mat2
mat2 %*% mat2 %*% mat2
mat2 %*% mat2 %*% mat2 %*% mat2
mat2 %*% mat2 %*% mat2 %*% mat2 %*% mat2
mh.gamma <- function(n.sims, start, burnin, cand.sd, shape, rate) {
theta.cur <- start
draws <- c()
theta.update <- function(theta.cur, shape, rate) {
theta.can <- rnorm(1, mean = theta.cur, sd = cand.sd)
accept.prob <- dgamma(theta.can, shape = shape, rate = rate)/dgamma(theta.cur,
shape = shape, rate = rate)
if (runif(1) <= accept.prob)
theta.can
else theta.cur
}
for (i in 1:n.sims) {
draws[i] <- theta.cur <- theta.update(theta.cur, shape = shape,
rate = rate)
}
return(draws[(burnin + 1):n.sims])
}
mh.draws <- mh.gamma(10000, start = 1, burnin = 1000, cand.sd = 2, shape = 1.7, rate = 4.4)
mh.draws
0.2/0.25
mat1 <- matrix(0, 6,6)
mat1[-c(5:6), -c(1:2)] <- diag(4)
mat1[1,2] <-1
mat1[5,6] <-1
mat1
mat1^2
mat2 %*% mat2 %*% mat2 %*% mat2
mat2 <- mat1 + diag(6)
mat2
mat2 %*% mat2 %*% mat2 %*% mat2 %*% mat2
mat1^2mat1
mat1
mat2 <- mat1 + t(mat1) #diag(6)
chord3 <- mat2 %*% mat2 %*% mat2 %*% mat2 %*% mat2
chord3 <- mat2 %*% mat2 %*% mat2 %*% mat2
chord3 <- chord3 +chord3 %*% mat2
chord3
mat2 <- mat1
chord3 <- mat2 %*% mat2 %*% mat2 %*% mat2
chord3 <- chord3 +chord3 %*% mat2
chord3
bigcor <- function(x, nblocks = 10, verbose = TRUE, par = TRUE, ...)
{
library(ff, quietly = TRUE)
NCOL <- ncol(x)
#sets saving options to the current directory for the temp file this prevents
#errors when using server based systems such as AWS that have write restrictions
## preallocate square matrix of dimension
## ncol(x) in 'ff' single format
corMAT <- ff(vmode = "single", dim = c(NCOL, NCOL))
print("Converted to ff matrix")
remainder <- nblocks-(NCOL %%nblocks)
groupsize <-(NCOL +remainder)/nblocks
## split column numbers into 'nblocks' groups
SPLIT <- split(1:NCOL, rep(1:nblocks,each=groupsize)[1:NCOL])
## create all unique combinations of blocks
COMBS <- expand.grid(1:length(SPLIT), 1:length(SPLIT))
COMBS <- t(apply(COMBS, 1, sort))
COMBS <- unique(COMBS)
print("unique combinations identified")
## iterate through each block combination, calculate correlation matrix
## between blocks and store them in the preallocated matrix on both
## symmetric sides of the diagonal
if(par){
mclapply(1:nrow(COMBS), function(i){
COMB <- COMBS[i, ]
G1 <- SPLIT[[COMB[1]]]
G2 <- SPLIT[[COMB[2]]]
if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
flush.console()
COR <- cor(x[, G1], x[, G2], ...)
corMAT[G1, G2] <- COR
corMAT[G2, G1] <- t(COR)
COR <- NULL
},
mc.cores = detectCores())
} else {
for (i in 1:nrow(COMBS)) {
COMB <- COMBS[i, ]
G1 <- SPLIT[[COMB[1]]]
G2 <- SPLIT[[COMB[2]]]
if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
flush.console()
COR <- cor(x[, G1], x[, G2], ...)
corMAT[G1, G2] <- COR
corMAT[G2, G1] <- t(COR)
COR <- NULL
}
}
gc()
return(corMAT)
}
#taken from http://www.r-bloggers.com/bigcor-large-correlation-matrices-in-r/
#It's questionable weather there is a point to parallelising this,
#as if you have enough RAM you don't need bigcor
bigcor <- function(x, nblocks = 10, verbose = TRUE, par = TRUE, ...)
{
library(ff, quietly = TRUE)
NCOL <- ncol(x)
#sets saving options to the current directory for the temp file this prevents
#errors when using server based systems such as AWS that have write restrictions
## preallocate square matrix of dimension
## ncol(x) in 'ff' single format
corMAT <- ff(vmode = "single", dim = c(NCOL, NCOL))
print("Converted to ff matrix")
remainder <- nblocks-(NCOL %%nblocks)
groupsize <-(NCOL +remainder)/nblocks
## split column numbers into 'nblocks' groups
SPLIT <- split(1:NCOL, rep(1:nblocks,each=groupsize)[1:NCOL])
## create all unique combinations of blocks
COMBS <- expand.grid(1:length(SPLIT), 1:length(SPLIT))
COMBS <- t(apply(COMBS, 1, sort))
COMBS <- unique(COMBS)
print("unique combinations identified")
## iterate through each block combination, calculate correlation matrix
## between blocks and store them in the preallocated matrix on both
## symmetric sides of the diagonal
if(par){
mclapply(1:nrow(COMBS), function(i){
COMB <- COMBS[i, ]
G1 <- SPLIT[[COMB[1]]]
G2 <- SPLIT[[COMB[2]]]
if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
flush.console()
COR <- cor(x[, G1], x[, G2], ...)
corMAT[G1, G2] <- COR
corMAT[G2, G1] <- t(COR)
COR <- NULL
},
mc.cores = detectCores())
} else {
for (i in 1:nrow(COMBS)) {
COMB <- COMBS[i, ]
G1 <- SPLIT[[COMB[1]]]
G2 <- SPLIT[[COMB[2]]]
if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
flush.console()
COR <- cor(x[, G1], x[, G2], ...)
corMAT[G1, G2] <- COR
corMAT[G2, G1] <- t(COR)
COR <- NULL
}
}
gc()
return(corMAT)
}
#taken from http://www.r-bloggers.com/bigcor-large-correlation-matrices-in-r/
#It's questionable weather there is a point to parallelising this,
#as if you have enough RAM you don't need bigcor
bigcor <- function(x, nblocks = 10, verbose = TRUE, par = FALSE, ...)
{
library(ff, quietly = TRUE)
NCOL <- ncol(x)
#sets saving options to the current directory for the temp file this prevents
#errors when using server based systems such as AWS that have write restrictions
## preallocate square matrix of dimension
## ncol(x) in 'ff' single format
corMAT <- ff(vmode = "single", dim = c(NCOL, NCOL))
print("Converted to ff matrix")
remainder <- nblocks-(NCOL %%nblocks)
groupsize <-(NCOL +remainder)/nblocks
## split column numbers into 'nblocks' groups
SPLIT <- split(1:NCOL, rep(1:nblocks,each=groupsize)[1:NCOL])
## create all unique combinations of blocks
COMBS <- expand.grid(1:length(SPLIT), 1:length(SPLIT))
COMBS <- t(apply(COMBS, 1, sort))
COMBS <- unique(COMBS)
print("unique combinations identified")
## iterate through each block combination, calculate correlation matrix
## between blocks and store them in the preallocated matrix on both
## symmetric sides of the diagonal
if(par){
mclapply(1:nrow(COMBS), function(i){
COMB <- COMBS[i, ]
G1 <- SPLIT[[COMB[1]]]
G2 <- SPLIT[[COMB[2]]]
if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
flush.console()
COR <- cor(x[, G1], x[, G2], ...)
corMAT[G1, G2] <- COR
corMAT[G2, G1] <- t(COR)
COR <- NULL
},
mc.cores = detectCores())
} else {
for (i in 1:nrow(COMBS)) {
COMB <- COMBS[i, ]
G1 <- SPLIT[[COMB[1]]]
G2 <- SPLIT[[COMB[2]]]
if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
flush.console()
COR <- cor(x[, G1], x[, G2], ...)
corMAT[G1, G2] <- COR
corMAT[G2, G1] <- t(COR)
COR <- NULL
}
}
gc()
return(corMAT)
}
#taken from http://www.r-bloggers.com/bigcor-large-correlation-matrices-in-r/
setwd(daytimeseries)
list.vertex.attributes(graph3)
?hms
library(lubridate)
?hms
packages <-c("plyr","stringr", "lubridate", "data.table","caret", "xgboost","e1071", "R.utils", "corrplot", "Hmisc", "Amelia", "Matrix", "ff", "ggdendro", "zoo", "networkD3", "igraph","parallel", "magrittr", "ggplot2", "tidyr", "xtable","dplyr")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
sapply(packages, library, character.only = TRUE)
rm(list=c("packages",  "new.packages"))
isAWS <-(Sys.info()[1]=="Linux")
# getwd()
# setwd("/home/rstudio")
# dir.create("Cormats")
# dir.create("graphs")
file.path("/home/rstudio", "Cormats")
file.path("/home/rstudio", "graphs")
```
Project Folders
```{r Paths}
#basewd needs to be changed
if(isAWS){
basewd<- "/home/rstudio/Dropbox/Thesis-Data"
Figures <- "/home/rstudio/Dropbox/Apps/ShareLaTeX/University College London thesis/Figures"
Figures <- file.path("/home/rstudio/Dropbox/Apps/ShareLaTeX/University-College-London-thesis/Figures")
functioncode <- file.path(basewd, "SmartMeterThesisCode","Functions")
Cormats <- "/home/rstudio/Cormats"
GraphPath<-file.path("/home/rstudio", "graphs")
options(fftempdir = "/home/rstudio")
} else {
basewd <- "C:/Users/pc1/Dropbox/Thesis-Data"
Figures <- file.path("C:/Users/pc1/Dropbox/Apps/ShareLaTeX/University-College-London-thesis/Figures")
functioncode <- "C:/Users/pc1/Dropbox/Thesis-Data/SmartMeterThesisCode/Functions"
Cormats <- "C:/Users/pc1/Dropbox/Thesis-Data/Cormats"
}
SubDataSets <- file.path(basewd, "SubDataSets")
datafile <- file.path(basewd, "TCa1")
daytimeseries <-file.path(basewd,"Cleandata")
#file.path(basewd,"Cormats")
```
Source functions
```{r Functions}
setwd(functioncode)
sapply(list.files(), source)
gc()
